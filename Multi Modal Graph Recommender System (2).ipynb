{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3f2431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/20 22:07:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting and saving item image URLs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 'item_images.parquet'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed and saved 'items_features.parquet' and 'user_item_edges.parquet'\n"
     ]
    }
   ],
   "source": [
    "# process_data.py\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, coalesce, lit, when,\n",
    "    collect_list, concat_ws, count,\n",
    "    lower, first\n",
    ")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train_recommender.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "\n",
    "# New imports for image processing\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process Amazon Fashion data and prepare it for a graph model.\n",
    "    \"\"\"\n",
    "    # Configure and create the Spark Session\n",
    "    conf = pyspark.SparkConf().setAll([\n",
    "        ('spark.driver.memory', '8g'),\n",
    "        ('spark.executor.memory', '8g')\n",
    "    ])\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"AmazonFashionGraphRecSys\") \\\n",
    "        .config(conf=conf) \\\n",
    "        .getOrCreate()\n",
    "    spark.conf.set(\"spark.sql.legacy.allowColonInFieldNames\", \"true\")\n",
    "\n",
    "    # Load the raw dataset\n",
    "    df_raw = spark.read.json(\"AMAZON_FASHION.json\")\n",
    "\n",
    "    # --- NEW: Extract and save item image URLs ---\n",
    "    print(\"Extracting and saving item image URLs...\")\n",
    "    df_item_images = df_raw.select(\n",
    "        col(\"asin\").alias(\"item_id\"),\n",
    "        col(\"image\")\n",
    "    ).distinct()\n",
    "    df_item_images.write.mode(\"overwrite\").parquet(\"item_images.parquet\")\n",
    "    print(\"Successfully saved 'item_images.parquet'\")\n",
    "    # --- End of New Section ---\n",
    "\n",
    "\n",
    "    # Select necessary columns and perform K-Core filtering\n",
    "    df_filtered = df_raw.select(\n",
    "        col(\"reviewerID\").alias(\"user_id\"),\n",
    "        col(\"asin\").alias(\"item_id\"),\n",
    "        col(\"overall\").alias(\"rating\"),\n",
    "        col(\"unixReviewTime\").alias(\"timestamp\"),\n",
    "        \"style\",\n",
    "        \"summary\",\n",
    "        \"reviewText\"\n",
    "    ).dropna(subset=[\"user_id\", \"item_id\"])\n",
    "\n",
    "    min_reviews_per_item = 5\n",
    "    min_reviews_per_user = 2\n",
    "    item_counts = df_filtered.groupBy(\"item_id\").count().where(col('count') >= min_reviews_per_item)\n",
    "    df_filtered = df_filtered.join(item_counts.select(\"item_id\"), on=\"item_id\", how=\"inner\")\n",
    "    user_counts = df_filtered.groupBy(\"user_id\").count().where(col('count') >= min_reviews_per_user)\n",
    "    df_filtered = df_filtered.join(user_counts.select(\"user_id\"), on=\"user_id\", how=\"inner\")\n",
    "\n",
    "    # Sample from the filtered dataset and cache it\n",
    "    df_subset = df_filtered.sample(withReplacement=False, fraction=0.6, seed=42)\n",
    "    df_subset.cache()\n",
    "\n",
    "    # --- Item Node Feature Engineering (No UDFs) ---\n",
    "    df_item_text = df_subset.groupBy(\"item_id\").agg(\n",
    "        concat_ws(\" \", collect_list(coalesce(col(\"summary\"), lit(\"\"))), collect_list(coalesce(col(\"reviewText\"), lit(\"\")))).alias(\"item_description\")\n",
    "    )\n",
    "\n",
    "    df_item_style = df_subset.groupBy(\"item_id\").agg(\n",
    "        first(\"style\").alias(\"style\")\n",
    "    ).select(\n",
    "        \"item_id\",\n",
    "        coalesce(\n",
    "            col(\"style.Style:\"), col(\"style.Style Name:\"), col(\"style.Scent Name:\"),\n",
    "            col(\"style.Size Name:\"), col(\"style.Material:\")\n",
    "        ).alias(\"product_type_from_style\"),\n",
    "        col(\"style.Color:\").alias(\"color\")\n",
    "    )\n",
    "\n",
    "    df_item_text = df_item_text.withColumn(\"desc_lower\", lower(col(\"item_description\")))\n",
    "    product_type_expr = (\n",
    "        when(col(\"desc_lower\").rlike(r'\\bdress(es)?\\b'), \"Dress\")\n",
    "        .when(col(\"desc_lower\").rlike(r'\\b(shoe|boot|sneaker|sandal|heel)s?\\b'), \"Shoes\")\n",
    "        .when(col(\"desc_lower\").rlike(r'\\b(shirt|top|blouse|t-shirt)s?\\b'), \"Top\")\n",
    "        .when(col(\"desc_lower\").rlike(r'\\b(pant|jean|short|bottom|skirt)s?\\b'), \"Bottoms\")\n",
    "        .when(col(\"desc_lower\").rlike(r'\\b(jacket|coat|outerwear)\\b'), \"Outerwear\")\n",
    "        .when(col(\"desc_lower\").rlike(r'\\b(bag|purse|wallet|accessory)\\b'), \"Accessory\")\n",
    "        .when(col(\"desc_lower\").rlike(r'\\b(jewelry|necklace|ring|earring)s?\\b'), \"Jewelry\")\n",
    "        .otherwise(\"Unknown_Fashion_Item\")\n",
    "    )\n",
    "    df_item_text = df_item_text.withColumn(\"product_type_from_text\", product_type_expr)\n",
    "\n",
    "    df_items = df_item_text.join(df_item_style, \"item_id\", \"left\").withColumn(\n",
    "        \"product_type\",\n",
    "        coalesce(col(\"product_type_from_style\"), col(\"product_type_from_text\"))\n",
    "    ).select(\n",
    "        \"item_id\", \"product_type\", \"color\", \"item_description\"\n",
    "    )\n",
    "\n",
    "    # --- Create Graph Edges ---\n",
    "    df_edges = df_subset.select(\n",
    "        col(\"user_id\"), col(\"item_id\"),\n",
    "        col(\"rating\").cast(\"float\"),\n",
    "        col(\"timestamp\").cast(\"long\")\n",
    "    ).distinct()\n",
    "\n",
    "    # Save the main feature and edge files\n",
    "    df_items.write.mode(\"overwrite\").parquet(\"items_features.parquet\")\n",
    "    df_edges.write.mode(\"overwrite\").parquet(\"user_item_edges.parquet\")\n",
    "\n",
    "    print(\"Successfully processed and saved 'items_features.parquet' and 'user_item_edges.parquet'\")\n",
    "\n",
    "    spark.stop()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7197ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      item_id product_type   color  \\\n",
      "0  B000085HZL    Accessory    None   \n",
      "1  B00008JOQI          Top    None   \n",
      "2  B00061RFTW      Jewelry    None   \n",
      "3  B00062NHH0          Top   White   \n",
      "4  B00063VWTY          Top    None   \n",
      "\n",
      "                                    item_description  \n",
      "0  Great Quality!!!!!! If you want a wallet to ho...  \n",
      "1  If only it had two cuff buttons! Five Stars Go...  \n",
      "2  Just right. I love this ring!! I have small fi...  \n",
      "3  I love these shirts. no V-Neck T-Shirt Calvin ...  \n",
      "4  Stylin'! Outstanding and well formed great rep...  \n"
     ]
    }
   ],
   "source": [
    "# Pandas can read the Parquet file directory seamlessly\n",
    "items_df = pd.read_parquet(\"items_features.parquet\")\n",
    "edges_df = pd.read_parquet(\"user_item_edges.parquet\")\n",
    "\n",
    "# Your DataFrame will be perfectly structured with no parsing errors.\n",
    "print(items_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdfb366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Encoding features...\n",
      "Generating image embeddings (this may take a while)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 154\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn [3], line 50\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(img_path):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_url\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(img_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # --- 1. Load the Data ---\n",
    "    print(\"Loading data...\")\n",
    "    items_df = pd.read_parquet(\"items_features.parquet\")\n",
    "    edges_df = pd.read_parquet(\"user_item_edges.parquet\")\n",
    "    try:\n",
    "        images_df = pd.read_parquet(\"item_images.parquet\")\n",
    "        images_df.rename(columns={'asin': 'item_id'}, inplace=True)\n",
    "        \n",
    "        # --- THIS IS THE CORRECTED LINE ---\n",
    "        # Explicitly check the size of the array to avoid ambiguity\n",
    "        images_df['image_url'] = images_df['image'].apply(\n",
    "            lambda x: x[0] if x is not None and x.size > 0 else None\n",
    "        )\n",
    "        # --- END OF CORRECTION ---\n",
    "\n",
    "        items_df = items_df.merge(images_df[['item_id', 'image_url']], on='item_id', how='left')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load image URLs, skipping image features. Error: {e}\")\n",
    "        items_df['image_url'] = None\n",
    "\n",
    "\n",
    "    # --- 2. Text and Categorical Feature Engineering & Encoding ---\n",
    "    print(\"Encoding features...\")\n",
    "    user_encoder = LabelEncoder()\n",
    "    item_encoder = LabelEncoder()\n",
    "    edges_df['user_idx'] = user_encoder.fit_transform(edges_df['user_id'])\n",
    "    edges_df['item_idx'] = item_encoder.fit_transform(edges_df['item_id'])\n",
    "    \n",
    "    items_df['item_idx'] = item_encoder.transform(items_df['item_id'])\n",
    "    items_df = items_df.sort_values('item_idx').set_index('item_idx')\n",
    "\n",
    "    items_df['item_description'] = items_df['item_description'].fillna('')\n",
    "    vectorizer = TfidfVectorizer(max_features=128)\n",
    "    description_encoded = vectorizer.fit_transform(items_df['item_description']).toarray()\n",
    "    text_features_tensor = torch.tensor(description_encoded, dtype=torch.float)\n",
    "\n",
    "    # --- 2a. Image Feature Engineering ---\n",
    "    print(\"Generating image embeddings (this may take a while)...\")\n",
    "    img_model = SentenceTransformer('clip-ViT-B-32')\n",
    "    \n",
    "    if not os.path.exists('images'):\n",
    "        os.makedirs('images')\n",
    "\n",
    "    image_embeddings = []\n",
    "    for idx, row in items_df.iterrows():\n",
    "        img_path = f\"images/{row['item_id']}.jpg\"\n",
    "        if row['image_url'] and not os.path.exists(img_path):\n",
    "            try:\n",
    "                response = requests.get(row['image_url'], stream=True, timeout=5)\n",
    "                if response.status_code == 200:\n",
    "                    with open(img_path, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "            except requests.exceptions.RequestException:\n",
    "                pass \n",
    "\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                img_emb = img_model.encode(Image.open(img_path))\n",
    "                image_embeddings.append(img_emb)\n",
    "            except Exception:\n",
    "                image_embeddings.append(np.zeros(512))\n",
    "        else:\n",
    "            image_embeddings.append(np.zeros(512))\n",
    "\n",
    "    image_features_tensor = torch.tensor(np.array(image_embeddings), dtype=torch.float)\n",
    "\n",
    "    # --- 2b. Combine All Features ---\n",
    "    print(\"Combining all features into a single tensor...\")\n",
    "    item_features_tensor = torch.cat([text_features_tensor, image_features_tensor], dim=1)\n",
    "\n",
    "    # --- 3. Construct Heterogeneous Graph ---\n",
    "    print(\"Constructing graph...\")\n",
    "    data = HeteroData()\n",
    "    data['user'].num_nodes = len(user_encoder.classes_)\n",
    "    data['item'].x = item_features_tensor\n",
    "    \n",
    "    edge_index_user_item = torch.tensor(edges_df[['user_idx', 'item_idx']].values.T, dtype=torch.long)\n",
    "    edge_ratings = torch.tensor(edges_df['rating'].values, dtype=torch.float)\n",
    "    data['user', 'rates', 'item'].edge_index = edge_index_user_item\n",
    "    data['user', 'rates', 'item'].edge_attr = edge_ratings\n",
    "\n",
    "    data = ToUndirected()(data)\n",
    "\n",
    "    # --- 4. Define the GraphSAGE Model ---\n",
    "    class GNNEncoder(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "            self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.conv1(x, edge_index).relu()\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return x\n",
    "\n",
    "    class EdgeDecoder(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels):\n",
    "            super().__init__()\n",
    "            self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "            self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "        def forward(self, z_dict, edge_label_index):\n",
    "            row, col = edge_label_index\n",
    "            z = torch.cat([z_dict['user'][row], z_dict['item'][col]], dim=-1)\n",
    "            z = self.lin1(z).relu()\n",
    "            z = self.lin2(z)\n",
    "            return z.view(-1)\n",
    "\n",
    "    class Model(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels, num_users):\n",
    "            super().__init__()\n",
    "            self.user_emb = torch.nn.Embedding(num_users, hidden_channels)\n",
    "            self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "            self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "            self.decoder = EdgeDecoder(hidden_channels)\n",
    "        def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "            user_x = self.user_emb(x_dict['user'])\n",
    "            x_dict_encoded = {\"user\": user_x, \"item\": x_dict[\"item\"]}\n",
    "            z_dict = self.encoder(x_dict_encoded, edge_index_dict)\n",
    "            return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "    model = Model(hidden_channels=64, num_users=data['user'].num_nodes)\n",
    "    \n",
    "    # --- 5. Train the Model ---\n",
    "    print(\"Training the model...\")\n",
    "    data['user'].x = torch.arange(data['user'].num_nodes)\n",
    "    transform = RandomLinkSplit(\n",
    "        is_undirected=True, num_val=0.1, num_test=0.1,\n",
    "        neg_sampling_ratio=0.0, add_negative_train_samples=False,\n",
    "        edge_types=[('user', 'rates', 'item')],\n",
    "        rev_edge_types=[('item', 'rev_rates', 'user')]\n",
    "    )\n",
    "    train_data, val_data, test_data = transform(data)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range(1, 51):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(\n",
    "            train_data.x_dict,\n",
    "            train_data.edge_index_dict,\n",
    "            train_data['user', 'item'].edge_label_index\n",
    "        )\n",
    "        target = train_data['user', 'item'].edge_attr\n",
    "        loss = F.mse_loss(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch:03d}, Loss (MSE): {loss:.4f}\")\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4002c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Encoding features...\n",
      "Creating combined item features...\n",
      "Constructing graph with temporal edges...\n",
      "Training the GAT model...\n",
      "Epoch: 010, Loss (MSE): 3.2756\n",
      "Epoch: 020, Loss (MSE): 1.6005\n",
      "Epoch: 030, Loss (MSE): 1.4835\n",
      "Epoch: 040, Loss (MSE): 1.3873\n",
      "Epoch: 050, Loss (MSE): 1.2959\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# train_recommender_gat.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "\n",
    "def main():\n",
    "    # --- 1. Load the Data ---\n",
    "    print(\"Loading data...\")\n",
    "    items_df = pd.read_parquet(\"items_features.parquet\")\n",
    "    edges_df = pd.read_parquet(\"user_item_edges.parquet\")\n",
    "\n",
    "    # --- 2. Feature Engineering & Encoding ---\n",
    "    print(\"Encoding features...\")\n",
    "    user_encoder = LabelEncoder()\n",
    "    item_encoder = LabelEncoder()\n",
    "    edges_df['user_idx'] = user_encoder.fit_transform(edges_df['user_id'])\n",
    "    edges_df['item_idx'] = item_encoder.fit_transform(edges_df['item_id'])\n",
    "    \n",
    "    items_df['item_idx'] = item_encoder.transform(items_df['item_id'])\n",
    "    items_df = items_df.sort_values('item_idx').set_index('item_idx')\n",
    "\n",
    "    # --- 2a. Re-combine Text and Categorical Features ---\n",
    "    print(\"Creating combined item features...\")\n",
    "    # Text features\n",
    "    items_df['item_description'] = items_df['item_description'].fillna('')\n",
    "    vectorizer = TfidfVectorizer(max_features=128)\n",
    "    description_encoded = vectorizer.fit_transform(items_df['item_description']).toarray()\n",
    "\n",
    "    # Categorical features\n",
    "    product_type_encoded = pd.get_dummies(items_df['product_type'], prefix='type').to_numpy()\n",
    "    color_encoded = pd.get_dummies(items_df['color'], prefix='color').to_numpy()\n",
    "\n",
    "    # Combine all features into a single matrix\n",
    "    combined_features = np.concatenate([description_encoded, product_type_encoded, color_encoded], axis=1)\n",
    "    item_features_tensor = torch.tensor(combined_features, dtype=torch.float)\n",
    "\n",
    "    # --- 2b. Normalize Timestamps ---\n",
    "    # Normalizing time features is crucial for stable training\n",
    "    scaler = StandardScaler()\n",
    "    edges_df['timestamp_scaled'] = scaler.fit_transform(edges_df[['timestamp']])\n",
    "\n",
    "\n",
    "    # --- 3. Construct Heterogeneous Graph with Time ---\n",
    "    print(\"Constructing graph with temporal edges...\")\n",
    "    data = HeteroData()\n",
    "\n",
    "    data['user'].num_nodes = len(user_encoder.classes_)\n",
    "    data['item'].x = item_features_tensor\n",
    "\n",
    "    # Add edges with ratings (edge_attr) and time (edge_time)\n",
    "    edge_index = torch.tensor(edges_df[['user_idx', 'item_idx']].values.T, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(edges_df['rating'].values, dtype=torch.float)\n",
    "    edge_time = torch.tensor(edges_df['timestamp_scaled'].values, dtype=torch.float).view(-1, 1) # Reshape for concatenation\n",
    "    \n",
    "    data['user', 'rates', 'item'].edge_index = edge_index\n",
    "    data['user', 'rates', 'item'].edge_attr = edge_attr\n",
    "    data['user', 'rates', 'item'].edge_time = edge_time # New temporal attribute\n",
    "\n",
    "    data = ToUndirected()(data)\n",
    "\n",
    "    # --- 4. Define the Graph Attention (GAT) Model ---\n",
    "    class GATEncoder(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.conv1 = GATConv((-1, -1), hidden_channels, heads=4, add_self_loops=False)\n",
    "            self.conv2 = GATConv((-1, -1), out_channels, heads=1, add_self_loops=False)\n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.conv1(x, edge_index).relu()\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return x\n",
    "\n",
    "    # The decoder is now time-aware and uses a clearer variable name\n",
    "    class EdgeDecoder(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels):\n",
    "            super().__init__()\n",
    "            self.lin1 = torch.nn.Linear(2 * hidden_channels + 1, hidden_channels)\n",
    "            self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "        # --- THIS IS CORRECTED ---\n",
    "        # Renamed 'edge_label_index' to 'supervision_edge_index' for clarity\n",
    "        def forward(self, z_dict, supervision_edge_index, edge_time):\n",
    "            row, col = supervision_edge_index\n",
    "        # --- END OF CORRECTION ---\n",
    "            z = torch.cat([z_dict['user'][row], z_dict['item'][col], edge_time], dim=-1)\n",
    "            z = self.lin1(z).relu()\n",
    "            z = self.lin2(z)\n",
    "            return z.view(-1)\n",
    "\n",
    "    class Model(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels, num_users):\n",
    "            super().__init__()\n",
    "            self.user_emb = torch.nn.Embedding(num_users, hidden_channels)\n",
    "            self.encoder = GATEncoder(hidden_channels, hidden_channels)\n",
    "            self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "            self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "        # --- THIS IS CORRECTED ---\n",
    "        # Renamed 'edge_label_index' to 'supervision_edge_index' for clarity\n",
    "        def forward(self, x_dict, edge_index_dict, supervision_edge_index, edge_time):\n",
    "        # --- END OF CORRECTION ---\n",
    "            user_x = self.user_emb(x_dict['user'])\n",
    "            x_dict_encoded = {\"user\": user_x, \"item\": x_dict[\"item\"]}\n",
    "            z_dict = self.encoder(x_dict_encoded, edge_index_dict)\n",
    "            return self.decoder(z_dict, supervision_edge_index, edge_time)\n",
    "\n",
    "    model = Model(hidden_channels=64, num_users=data['user'].num_nodes)\n",
    "\n",
    "    # --- 5. Train the Model ---\n",
    "    print(\"Training the GAT model...\")\n",
    "    data['user'].x = torch.arange(data['user'].num_nodes)\n",
    "\n",
    "    transform = RandomLinkSplit(\n",
    "        is_undirected=True, num_val=0.1, num_test=0.1,\n",
    "        neg_sampling_ratio=0.0, add_negative_train_samples=False,\n",
    "        edge_types=[('user', 'rates', 'item')],\n",
    "        rev_edge_types=[('item', 'rev_rates', 'user')],\n",
    "        key='edge_time'\n",
    "    )\n",
    "    train_data, val_data, test_data = transform(data)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    edge_type = ('user', 'rates', 'item')\n",
    "\n",
    "    for epoch in range(1, 51):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # --- THIS BLOCK IS CORRECTED ---\n",
    "        # We pass the training data's own 'edge_index' for supervision\n",
    "        pred = model(\n",
    "            train_data.x_dict,\n",
    "            train_data.edge_index_dict,\n",
    "            train_data[edge_type].edge_index, # Use edge_index, NOT edge_label_index\n",
    "            train_data[edge_type].edge_time\n",
    "        )\n",
    "        target = train_data[edge_type].edge_attr\n",
    "        # --- END OF CORRECTION ---\n",
    "\n",
    "        loss = F.mse_loss(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch:03d}, Loss (MSE): {loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d32c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def analyze_user_communities(model, edge_index_full, user_encoder):\n",
    "    \"\"\"\n",
    "    Analyzes and visualizes user communities from trained LightGCN embeddings.\n",
    "    Args:\n",
    "            model: The trained LightGCN model object.\n",
    "            edge_index_full: The full edge index used for training.\n",
    "            user_encoder: The fitted LabelEncoder for users.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting User Community Analysis ---\")\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # 1. Extract the final user embeddings from the trained encoder\n",
    "    with torch.no_grad():\n",
    "        final_user_emb, _ = model.encoder(edge_index_full)\n",
    "    user_embeddings_np = final_user_emb.cpu().numpy()\n",
    "    print(f\"Extracted {user_embeddings_np.shape[0]} user embeddings of dimension {user_embeddings_np.shape[1]}.\")\n",
    "\n",
    "    # 2. Use t-SNE to reduce the embeddings from 64D to 2D for plotting\n",
    "    # Perplexity is a key parameter; a good starting point is around 30-50.\n",
    "    print(\"Performing t-SNE dimensionality reduction (this can take a moment)...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=300, init='pca')\n",
    "    user_embeddings_2d = tsne.fit_transform(user_embeddings_np)\n",
    "    print(\"t-SNE complete.\")\n",
    "\n",
    "    # 3. Create a scatter plot to visualize the user communities\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    sns.scatterplot(\n",
    "        x=user_embeddings_2d[:, 0],\n",
    "        y=user_embeddings_2d[:, 1],\n",
    "        s=30,          # Set marker size\n",
    "        alpha=0.6,     # Set marker transparency\n",
    "        edgecolor='none' # Remove marker borders for a cleaner look\n",
    "    )\n",
    "    plt.title('User Communities Visualized with t-SNE', fontsize=16)\n",
    "    plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "    plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "837b193c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Encoding features...\n",
      "Constructing graph with temporal edges...\n",
      "Training the LightGCN model (Optimizing for Ranking)...\n",
      "Epoch: 010, Loss (BPR): 0.3728\n",
      "Epoch: 020, Loss (BPR): 0.2710\n",
      "Epoch: 030, Loss (BPR): 0.2035\n",
      "Epoch: 040, Loss (BPR): 0.1741\n",
      "Epoch: 050, Loss (BPR): 0.1551\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8622/8622 [00:01<00:00, 5358.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results -> RMSE: 6.8781, Recall: 0.5514, NDCG: 0.4230\n"
     ]
    }
   ],
   "source": [
    "# train_recommender_lightgcn_bpr.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def main():\n",
    "    # --- 1. Load the Data ---\n",
    "    print(\"Loading data...\")\n",
    "    items_df = pd.read_parquet(\"items_features.parquet\")\n",
    "    edges_df = pd.read_parquet(\"user_item_edges.parquet\")\n",
    "\n",
    "    # --- 2. Feature Engineering & Encoding ---\n",
    "    print(\"Encoding features...\")\n",
    "    user_encoder = LabelEncoder()\n",
    "    item_encoder = LabelEncoder()\n",
    "    edges_df['user_idx'] = user_encoder.fit_transform(edges_df['user_id'])\n",
    "    edges_df['item_idx'] = item_encoder.fit_transform(edges_df['item_id'])\n",
    "    \n",
    "    items_df['item_idx'] = item_encoder.transform(items_df['item_id'])\n",
    "    items_df = items_df.sort_values('item_idx').set_index('item_idx')\n",
    "\n",
    "    # Create combined item features\n",
    "    items_df['item_description'] = items_df['item_description'].fillna('')\n",
    "    vectorizer = TfidfVectorizer(max_features=128)\n",
    "    description_encoded = vectorizer.fit_transform(items_df['item_description']).toarray()\n",
    "    product_type_encoded = pd.get_dummies(items_df['product_type'], prefix='type').to_numpy()\n",
    "    color_encoded = pd.get_dummies(items_df['color'], prefix='color').to_numpy()\n",
    "    combined_features = np.concatenate([description_encoded, product_type_encoded, color_encoded], axis=1)\n",
    "    \n",
    "    # Normalize Timestamps\n",
    "    scaler = StandardScaler()\n",
    "    edges_df['timestamp_scaled'] = scaler.fit_transform(edges_df[['timestamp']])\n",
    "\n",
    "    # --- 3. Construct Heterogeneous Graph with Time ---\n",
    "    print(\"Constructing graph with temporal edges...\")\n",
    "    data = HeteroData()\n",
    "    data['user'].num_nodes = len(user_encoder.classes_)\n",
    "    data['item'].x = torch.tensor(combined_features, dtype=torch.float)\n",
    "    \n",
    "    edge_index = torch.tensor(edges_df[['user_idx', 'item_idx']].values.T, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(edges_df['rating'].values, dtype=torch.float)\n",
    "    edge_time = torch.tensor(edges_df['timestamp_scaled'].values, dtype=torch.float).view(-1, 1)\n",
    "    \n",
    "    data['user', 'rates', 'item'].edge_index = edge_index\n",
    "    data['user', 'rates', 'item'].edge_attr = edge_attr\n",
    "    data['user', 'rates', 'item'].edge_time = edge_time\n",
    "\n",
    "    data = ToUndirected()(data)\n",
    "\n",
    "    # --- 4. Define the LightGCN Model (With Biases) ---\n",
    "    class LightGCN(torch.nn.Module):\n",
    "        def __init__(self, num_users, num_items, hidden_channels, num_layers):\n",
    "            super().__init__()\n",
    "            self.num_users = num_users\n",
    "            self.num_items = num_items\n",
    "            self.num_layers = num_layers\n",
    "            self.hidden_channels = hidden_channels\n",
    "\n",
    "            self.user_emb = torch.nn.Embedding(num_users, hidden_channels)\n",
    "            self.item_emb = torch.nn.Embedding(num_items, hidden_channels)\n",
    "            \n",
    "            self.convs = torch.nn.ModuleList(\n",
    "                [GCNConv(hidden_channels, hidden_channels, normalize=True) for _ in range(num_layers)]\n",
    "            )\n",
    "\n",
    "            torch.nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "            torch.nn.init.normal_(self.item_emb.weight, std=0.1)\n",
    "\n",
    "        def forward(self, edge_index):\n",
    "            user_emb = self.user_emb.weight\n",
    "            item_emb = self.item_emb.weight\n",
    "            \n",
    "            out_user_emb = user_emb\n",
    "            out_item_emb = item_emb\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                all_emb = torch.cat([user_emb, item_emb], dim=0)\n",
    "                all_emb = self.convs[i](all_emb, edge_index)\n",
    "                user_emb, item_emb = torch.split(all_emb, [self.num_users, self.num_items])\n",
    "                out_user_emb = out_user_emb + user_emb\n",
    "                out_item_emb = out_item_emb + item_emb\n",
    "\n",
    "            return out_user_emb / (self.num_layers + 1), out_item_emb / (self.num_layers + 1)\n",
    "\n",
    "    class EdgeDecoder(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels):\n",
    "            super().__init__()\n",
    "            self.lin1 = torch.nn.Linear(2 * hidden_channels + 1, hidden_channels)\n",
    "            self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "        def forward(self, user_emb, item_emb, edge_time):\n",
    "            z = torch.cat([user_emb, item_emb, edge_time], dim=-1)\n",
    "            z = self.lin1(z).relu()\n",
    "            z = self.lin2(z)\n",
    "            return z.view(-1)\n",
    "\n",
    "    class Model(torch.nn.Module):\n",
    "        def __init__(self, num_users, num_items, hidden_channels, num_layers=3):\n",
    "            super().__init__()\n",
    "            self.encoder = LightGCN(num_users, num_items, hidden_channels, num_layers)\n",
    "            self.decoder = EdgeDecoder(hidden_channels)\n",
    "            \n",
    "            # Biases are still useful for ranking (popular items rank higher)\n",
    "            self.user_bias = torch.nn.Embedding(num_users, 1)\n",
    "            self.item_bias = torch.nn.Embedding(num_items, 1)\n",
    "            self.global_bias = torch.nn.Parameter(torch.tensor(0.0)) \n",
    "            \n",
    "            torch.nn.init.zeros_(self.user_bias.weight)\n",
    "            torch.nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "        def forward(self, edge_index, u_indices, i_indices, edge_time):\n",
    "            # Generalized forward pass for specific user/item pairs\n",
    "            final_user_emb, final_item_emb = self.encoder(edge_index)\n",
    "            \n",
    "            user_emb_sup = final_user_emb[u_indices]\n",
    "            item_emb_sup = final_item_emb[i_indices]\n",
    "            \n",
    "            pred = self.decoder(user_emb_sup, item_emb_sup, edge_time)\n",
    "            \n",
    "            u_bias = self.user_bias(u_indices).squeeze()\n",
    "            i_bias = self.item_bias(i_indices).squeeze()\n",
    "            \n",
    "            return pred + u_bias + i_bias + self.global_bias\n",
    "\n",
    "    num_users = data['user'].num_nodes\n",
    "    num_items = data['item'].num_nodes\n",
    "    model = Model(num_users, num_items, hidden_channels=64, num_layers=3)\n",
    "    \n",
    "    # --- 5. Train the Model with BPR LOSS ---\n",
    "    print(\"Training the LightGCN model (Optimizing for Ranking)...\")\n",
    "    \n",
    "    # Ensure we have test negatives for evaluation, but keep train simple\n",
    "    transform = RandomLinkSplit(\n",
    "        is_undirected=True, num_val=0.1, num_test=0.1,\n",
    "        neg_sampling_ratio=1.0, \n",
    "        add_negative_train_samples=False, # We will sample train negatives dynamically\n",
    "        edge_types=[('user', 'rates', 'item')],\n",
    "        rev_edge_types=[('item', 'rev_rates', 'user')]\n",
    "    )\n",
    "    train_data, val_data, test_data = transform(data)\n",
    "    \n",
    "    # Graph Structure for propagation\n",
    "    u_idx, i_idx = data['user', 'rates', 'item'].edge_index\n",
    "    i_idx_offset = i_idx + num_users\n",
    "    edge_index_full = torch.cat([\n",
    "        torch.stack([u_idx, i_idx_offset]),\n",
    "        torch.stack([i_idx_offset, u_idx])\n",
    "    ], dim=1)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005) # Slightly lower LR for BPR\n",
    "    edge_type = ('user', 'rates', 'item')\n",
    "\n",
    "    for epoch in range(1, 51):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Get Positive Samples (Users and Items they liked)\n",
    "        pos_edge_index = train_data[edge_type].edge_index\n",
    "        pos_u = pos_edge_index[0]\n",
    "        pos_i = pos_edge_index[1]\n",
    "        # For time-aware BPR, we reuse the timestamp of the positive interaction\n",
    "        # This assumes \"At time T, User preferred Item Pos over Item Neg\"\n",
    "        pos_time = train_data[edge_type].edge_time\n",
    "        \n",
    "        # 2. Sample Negative Items (Items users probably didn't interact with)\n",
    "        # Simple random sampling: 1 negative for every positive\n",
    "        neg_i = torch.randint(0, num_items, (pos_u.size(0),))\n",
    "        \n",
    "        # 3. Compute Scores\n",
    "        # We need to calculate: Score(Pos) and Score(Neg)\n",
    "        \n",
    "        # Note: For efficiency in large graphs, we usually run encoder ONCE per batch\n",
    "        # But here we pass the full graph, so we can just get embeddings once\n",
    "        final_user_emb, final_item_emb = model.encoder(edge_index_full)\n",
    "        \n",
    "        # Helper to calculate score without re-running encoder\n",
    "        def get_score(u_idx, i_idx, t):\n",
    "            u_emb = final_user_emb[u_idx]\n",
    "            i_emb = final_item_emb[i_idx]\n",
    "            pred = model.decoder(u_emb, i_emb, t)\n",
    "            u_b = model.user_bias(u_idx).squeeze()\n",
    "            i_b = model.item_bias(i_idx).squeeze()\n",
    "            return pred + u_b + i_b # global_bias cancels out in BPR diff\n",
    "        \n",
    "        pos_scores = get_score(pos_u, pos_i, pos_time)\n",
    "        neg_scores = get_score(pos_u, neg_i, pos_time)\n",
    "        \n",
    "        # 4. BPR Loss: -log(sigmoid(pos - neg))\n",
    "        loss = -torch.mean(torch.nn.functional.logsigmoid(pos_scores - neg_scores))\n",
    "        \n",
    "        # L2 Regularization\n",
    "        l2_loss = 1e-4 * (model.encoder.user_emb.weight.norm(2) + model.encoder.item_emb.weight.norm(2))\n",
    "        loss += l2_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch:03d}, Loss (BPR): {loss:.4f}\")\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "    \n",
    "    # --- Testing Function (Unchanged, assuming 'test_model' is defined as in previous steps) ---\n",
    "    # Copying the robust test_model function here for completeness\n",
    "    def test_model(model, test_data, data, k=10, num_negatives=100):\n",
    "        model.eval()\n",
    "        device = next(model.parameters()).device\n",
    "        edge_type = ('user', 'rates', 'item')\n",
    "\n",
    "        # Pre-process Rating Lookup\n",
    "        src, dst = data[edge_type].edge_index\n",
    "        ratings = data[edge_type].edge_attr\n",
    "        rating_lookup = {(u.item(), i.item()): r.item() for u, i, r in zip(src.cpu(), dst.cpu(), ratings.cpu())}\n",
    "\n",
    "        # Construct Graph\n",
    "        u_idx, i_idx = test_data[edge_type].edge_index\n",
    "        num_users = data['user'].num_nodes\n",
    "        i_idx_offset = i_idx + num_users\n",
    "        test_msg_edge_index = torch.cat([torch.stack([u_idx, i_idx_offset]), torch.stack([i_idx_offset, u_idx])], dim=1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            final_user_emb, final_item_emb = model.encoder(test_msg_edge_index)\n",
    "\n",
    "        # RMSE\n",
    "        if not hasattr(test_data[edge_type], 'edge_label_index'): raise AttributeError(\"Missing edge_label_index\")\n",
    "        test_u_all, test_i_all = test_data[edge_type].edge_label_index\n",
    "        labels = test_data[edge_type].edge_label\n",
    "        pos_mask = labels == 1\n",
    "        test_u = test_u_all[pos_mask]\n",
    "        test_i = test_i_all[pos_mask]\n",
    "\n",
    "        targets = []\n",
    "        valid_indices = []\n",
    "        test_u_cpu = test_u.cpu().numpy()\n",
    "        test_i_cpu = test_i.cpu().numpy()\n",
    "\n",
    "        for idx, (u, i) in enumerate(zip(test_u_cpu, test_i_cpu)):\n",
    "            if (u, i) in rating_lookup:\n",
    "                targets.append(rating_lookup[(u, i)])\n",
    "                valid_indices.append(idx)\n",
    "\n",
    "        if targets:\n",
    "            targets = torch.tensor(targets, device=device)\n",
    "            test_u = test_u[valid_indices]\n",
    "            test_i = test_i[valid_indices]\n",
    "            test_times = torch.zeros((len(test_u), 1), device=device)\n",
    "            with torch.no_grad():\n",
    "                batch_user_emb = final_user_emb[test_u]\n",
    "                batch_item_emb = final_item_emb[test_i]\n",
    "                preds = model.decoder(batch_user_emb, batch_item_emb, test_times)\n",
    "                u_bias = model.user_bias(test_u).squeeze()\n",
    "                i_bias = model.item_bias(test_i).squeeze()\n",
    "                preds = preds + u_bias + i_bias + model.global_bias\n",
    "                rmse = np.sqrt(mean_squared_error(targets.cpu().numpy(), preds.cpu().numpy()))\n",
    "        else: rmse = 0.0\n",
    "\n",
    "        # Ranking\n",
    "        user_indices = test_u.cpu().numpy()\n",
    "        item_indices = test_i.cpu().numpy()\n",
    "        recalls = []\n",
    "        ndcgs = []\n",
    "        num_total_items = final_item_emb.shape[0]\n",
    "\n",
    "        for i in tqdm(range(len(user_indices))):\n",
    "            u_idx = user_indices[i]\n",
    "            pos_i_idx = item_indices[i]\n",
    "            neg_candidates = []\n",
    "            while len(neg_candidates) < num_negatives:\n",
    "                neg = random.randint(0, num_total_items - 1)\n",
    "                if neg != pos_i_idx: neg_candidates.append(neg)\n",
    "            \n",
    "            batch_u = torch.tensor([u_idx] * (num_negatives + 1), device=device)\n",
    "            batch_i = torch.tensor([pos_i_idx] + neg_candidates, device=device)\n",
    "            batch_t = torch.zeros((num_negatives + 1, 1), device=device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                u_emb = final_user_emb[batch_u]\n",
    "                i_emb = final_item_emb[batch_i]\n",
    "                scores = model.decoder(u_emb, i_emb, batch_t).cpu()\n",
    "                u_b = model.user_bias(batch_u).squeeze().cpu()\n",
    "                i_b = model.item_bias(batch_i).squeeze().cpu()\n",
    "                scores = scores + u_b + i_b + model.global_bias.cpu()\n",
    "                scores = scores.numpy()\n",
    "\n",
    "            gt_score = scores[0]\n",
    "            rank = np.sum(scores > gt_score) + 1\n",
    "            if rank <= k:\n",
    "                recalls.append(1.0)\n",
    "                ndcgs.append(1.0 / np.log2(rank + 1))\n",
    "            else:\n",
    "                recalls.append(0.0)\n",
    "                ndcgs.append(0.0)\n",
    "        # Post-processing strictly for display purposes\n",
    "        min_score = scores.min()\n",
    "        max_score = scores.max()\n",
    "\n",
    "        # Map to 1-5 range\n",
    "        display_stars = 1 + 4 * (scores - min_score) / (max_score - min_score)\n",
    "\n",
    "        return rmse, np.mean(recalls), np.mean(ndcgs)\n",
    "\n",
    "    # Run Test\n",
    "    from sklearn.metrics import mean_squared_error # Ensure import\n",
    "    rmse, recall, ndcg = test_model(model, test_data, data, k=10)\n",
    "    print(f\"Final Results -> RMSE: {rmse:.4f}, Recall: {recall:.4f}, NDCG: {ndcg:.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03233f39",
   "metadata": {},
   "source": [
    "Ultimately, recommender models should be optimized to improve an individualized ranking rather than predicting good ratings. When training and testing using metrics such as recall and ndcg, these models are better at actually surfacing movies users would like to watch. After implementing these changes, the model achieves recall of 0.5537 and 0.4262 on Recall and NDCG respectively. These results prove that the model is highly effective at putting the items a user effectively likes into their Top 10 list. It is performing 5.5x better than random chance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
